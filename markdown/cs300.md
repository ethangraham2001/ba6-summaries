---
title: CS-300 Data Intensive Systems Summary
author: Ethan Graham
date: \today
---

# Lecture 01: Introduction

## Declarative Language vs. Imperative Language

We can think of a declarative language, like SQL, as one wherein we specify
*"what we want the result to look like"* instead of specifying the exact steps
and we expect the result to be returned. This differs from an imperative
language, like C or anything other general purpose programming language, wherein
we specify all the steps and logic to be executed.

## What we want in a DBMS

A DBMS is expected to provide efficient, reliable, convenient and safe
multi-user storage/access to massive amounts of persistent data. We should be
able to keep our physical data indepent of low-level implementation, and 
accessible through high-level query languages/APIs.

### DBMS vs Filesystem

A file system suffers from problems of unpredictability.
If two users are editing the same file and both changes are saved at the same 
time, in general we don't know which change will survive. Similarly, if a user
is updating a file and the power goes out, knowing which changes will survive is
undefined. So how do we write data over a subsystem when it can only promise you
undefined behavior?

So what more could we want than a filesystem? 

- Simple and efficient ad-hoc queries
- Concurrency control
- Recovery
- Benefits of being able to model the data; i.e. being able to connect the
conceptual to the physical in a non-binding way.

DBMS offers the following intellectual contributions:

- **Representation** through data modeling
- **Languages and systems** for querying data, which allows for complex queires
over massive amounts of data.
- **Concurrency control** for data manpulation, allowing for controlled accesses
and transactional semantics.
- **Reliability** of data storage, maintaining semantics even after pulling the
plug on it.

A data-intensive application sits on top of a DBMS, i.e. it is built with the
underlying system in mind.

## DBMS Architecture

Conceptual design -> Logical design -> physical design -> Database
storage.

### Describing data

A **data model** is a collection of concepts used for describing data, hiding
low-level storage detail. We represent it relationally, hierarchically, 
as a graph, etc... A hierarchical data model would be something like JSON, with
nested information *(not everything can fit in a structured table!)*.

### Relational data model

This is the model we are interested for the time being. We think of it as a set
of records

- **Relation** which is a table with rows and columns
- **Schema** which describes the structure of the data *(the columns)*

We can think of the schema as a type, and the data as a variable *(link with
imperative programming languages)*.

## Levels of abstraction (from high to low)

- **External schema** is what the user sees
- **Logical schema** which is conceptual. This is what the application will see.
Think of it as a view in Django, for example.
- **Physical schema** which is internal, is the data is physically stored on 
disk. This includes files, indexes, ... Relations are stored as unordered files, 
with indexes on columns for example.

A DBMS cares about data indepdendence types

- **Data independence:** We can change the schema at one level of the DB without
changing the schema at the level above it.
- **Logical data independence** we can change the conceptual schema without
changing the user views
- **Physical data independence** we can change the internal schema without
having to change the conceptual schema or user views.

## ER Model

This is the conceptual design, therefore we concern ourselves with the 
following:

- What are the entities and relationships?
- What information about these entities and relationships should we store?
- What integrity constraints should hold? I.e. we should be doing something when
something doesn't hold, i.e. relationship points to an entity that doesn't exist

The ER diagram can be mapped to a relational schema; i.e. the ER isn't 
implemented directly as it is purely conceptual, but is realized via 
implementation.

### The entity, and the entity set

- **Entity** is a real-world object that is distinguishable from others, and is
stored in a DB using a set of attributes
- **Entity set** is a collection of similar entities *(e.g. employees)* which
all have the same set of attributes. Each entity in a set has a *key* and each
attribute has a *domain*.

### Relationship and relationship set

- **Relationship** is an association among two or more entities; a row 
contains the keys of the entities participating. It can contain attributes which
provide information about the relationship *(e.g. `since` which gives 
information on when the relationship started)*.

## Contraints in ER model

### Key constraints

This is where we introduce the following 

- Many-to-many: employee can work in many departments. A department can have 
many employees
- One-to-many: each department has at most one manager
- One-to-one: Each driver can drive at most one vehicle, and each vehicle has
at most one driver.

## Participation constraints

We introduce

- total participation: every employee should work in at least one department
- partial participation: there could be some employees who are not managers

## Weak Entity

## Design Considerations

A weak entity is one who can be identified uniquely only by considering the 
primary key of another owner entity. The owner set and the weak entity set
must participate in a one-to-many relationship (one owner, many weak entities),
and weak entity set must have total participation in this relationship.

### ISA hierarchies

Think of it as inheritance. For example *contract employees ISA employees*, 
signifying that a contracted employee is an employee. This allows us to add
descriptive attributes to subclasses without needing to add them to the parent
class. We define

- **Overlap contraints:** "can an hourly employee be a contract employee as
well?" -> allow or disallow
- **Covering contraints:** does every employee entity also have to be either
an hourly or contract employee? -> yes or no


### Aggregation

We can treat a relationship set as an entity set for the purpose of 
participation in other relationships.


### Entity vs. Attribute

If we consider that an `Employee` has a single `Address`, then it could make 
sense to have it as an attribute of `Employee`. However, in the case that an 
`Employee` has multiple, we should make a new table for `Address` and have
them both participate in a relationship, perhaps `Lives_at`.

### Final Notes

The above considerations are important during design, and are all subjective.

# Lecture 02 relational model

This is the model that has prevailed for most use cases.

- Models complex data in a very simple structure that is easy to reason about
- We can make arbitrarily complex queries with relative ease

Recently, NoSQL DBs have been gaining in popularity

- Function as key value stores
- Skips the transaction part -> great scalability for analytic workloads

## Basics

- **Schema:** structural description of the relations in a database.
- **Instance:** Actual contents at a given point in time. Includes
cardinality *(number of rows)* and arity/degree *(number of attributes)*

We introduce a `NULL` value that indicates an unknown or undefined attribute,
but this introduces complexity. If I filter for `gpa >= 3.4`, where does `NULL`
sit in the predicate?

## Keys

- **Superkey:** set of attributes s.t. no two distinct tuples can have the same
values in all key fields *(not necessarily minimal)*
- **Key:** Which is a minimal superkey
- **Candidate key:** If there are multiple keys, each is refered to as a 
candidate key.
- **Primary key:** the candidate key that is chosen by the DBA *(database 
admin)*

We note that everything is checked when we insert something

- Check all new values being inserted against the schema
- check all previous values for duplicates

This is a huge performance stop in the critical path of execution. Integrity
constraints are expensive, and an insert isn't completed until the check has
finished. Ideally, this should happen very quickly.

In SQL, consider the following:

```sql
CREATE TABLE Person
    (ssn CHAR(9),
     name CHAR(20),
     licence_num CHAR(10),
     PRIMARY KEY(ssn),
     UNIQUE(licence_num))
```

Where `UNIQUE(licence_num)` tells us that although it isn't the primary key, it
should be unique for all instances.

### Foreign Keys

Set of fields in one relation that is used to refer to a tuple in another 
relation *(corresponds to primary key of the other relation)*. Works like a
pointer. If all foreign key constraints are enforced, we achieve referential
integrity which basically means no dangling pointers.

Referential integrity is hard to maintain as data changes... "if a `Student` is
deleted, should we delete all `Enrolled` tuples that depend on it? Do we change
these `Enrolled` to include a default `sid`?

### Integrity Constraints -> IC
 
Condition that must be true for any instance of the database. A **legal** 
instance of a relation is one that satisfies all specified ICs.

## Relational Algebra

***"Mathematics is the best query language"***

A query is applied to relation instances, and the result of said query is also
a relation instance. Schemas in the input are fixed, and the schema for the
result is as well.

### Operations

#### Selection $\sigma$

For example

$$
\sigma_{rating < 9}(s_2)
$$

will select all rows in table $s_2$ that have a rating lower than 9.

#### Projection $\pi$

For example

$$
\pi_{sname, rating}(s_2)
$$

selects colums `sname` and `rating` from $s_2$. The projection operator removes 
duplicates because the output should always be a set.

#### Cross product $\times$

$$
S_1 \times R_1
$$

will yield each row of $S_1$ paired with each row of $R_1$. These two tables
may have a naming conflict *(an attribute with the same name)* -> in this case
we should rename the attribute for one/both of them.

#### Join

Compound operator that involves cross product, selection, and sometimes 
projection.

- Compute $R \times S$
- Select rows where attributes that appear in both relations have equal values
- project all unique attributes and one copy of each of the common ones *(for
example $R$ and $S$ both have an attribute `sid`, in this case we will remove
one duplicate).

#### Condition Join or Theta-Join

$$
R \bowtie_C S = \sigma_C (R \times S)
$$

The output schema is the same as that of the cross product, we just select rows
that satisfy some condition.

We also define the equi-join which is a special case of the theta-join wherein
we have a conjunction of equalities.

$$
S_1 \bowtie_{S_1.age = S_2.age}
$$

#### Division operator

$A / B$ contains all tuples $x$ such that for every tuple $y \in B$, 
$\exists xy \in A$

